{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"02-CNN-MNIST.ipynb","provenance":[]},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# <!-- TITLE --> [MNIST2] - Simple classification with CNN\n<!-- DESC --> An example of classification using a convolutional neural network for the famous MNIST dataset\n<!-- AUTHOR : Jean-Luc Parouty (CNRS/SIMaP) -->\n\n## Objectives :\n - Recognizing handwritten numbers\n - Understanding the principle of a classifier DNN network \n - Implementation with Keras \n\n\nThe [MNIST dataset](http://yann.lecun.com/exdb/mnist/) (Modified National Institute of Standards and Technology) is a must for Deep Learning.  \nIt consists of 60,000 small images of handwritten numbers for learning and 10,000 for testing.\n\n\n## What we're going to do :\n\n - Retrieve data\n - Preparing the data\n - Create a model\n - Train the model\n - Evaluate the result\n","metadata":{"id":"4iBhC26_bQHy"}},{"cell_type":"markdown","source":"## Step 1 - Init python stuff","metadata":{"id":"i8jx4qX1bQH3"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.datasets import mnist\n\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport sys,os\nfrom importlib import reload\n","metadata":{"id":"7T558x28bQH3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2 - Retrieve data\nMNIST is one of the most famous historic dataset.  \nInclude in [Keras datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets)","metadata":{"id":"t69pEPa9bQH7"}},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = x_train.reshape(-1,28,28,1)\nx_test  = x_test.reshape(-1,28,28,1)\n\nprint(\"x_train : \",x_train.shape)\nprint(\"y_train : \",y_train.shape)\nprint(\"x_test  : \",x_test.shape)\nprint(\"y_test  : \",y_test.shape)","metadata":{"id":"8K5fdAkRbQH8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3 - Preparing the data","metadata":{"id":"giNQx2E0bQH8"}},{"cell_type":"code","source":"print('Before normalization : Min={}, max={}'.format(x_train.min(),x_train.max()))\n\nxmax=x_train.max()\nx_train = x_train / xmax\nx_test  = x_test  / xmax\n\nprint('After normalization  : Min={}, max={}'.format(x_train.min(),x_train.max()))","metadata":{"id":"RAYcJhJAbQH9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Have a look","metadata":{"id":"cp_aZWRbbQH9"}},{"cell_type":"code","source":"def plot_images(x,y=None, indices='all', columns=12, x_size=1, y_size=1,\n                colorbar=False, y_pred=None, cm='binary', norm=None, y_padding=0.35, spines_alpha=1,\n                fontsize=20, interpolation='lanczos'):\n \n    if indices=='all': indices=range(len(x))\n    if norm and len(norm) == 2: norm = matplotlib.colors.Normalize(vmin=norm[0], vmax=norm[1])\n    draw_labels = (y is not None)\n    draw_pred   = (y_pred is not None)\n    rows        = math.ceil(len(indices)/columns)\n    fig=plt.figure(figsize=(columns*x_size, rows*(y_size+y_padding)))\n    n=1\n    for i in indices:\n        axs=fig.add_subplot(rows, columns, n)\n        n+=1\n        xx=x[i]\n        # ---- Shape is (lx,ly)\n        if len(x[i].shape)==2:\n            xx=x[i]\n        # ---- Shape is (lx,ly,n)\n        if len(x[i].shape)==3:\n            (lx,ly,lz)=x[i].shape\n            if lz==1: \n                xx=x[i].reshape(lx,ly)\n            else:\n                xx=x[i]\n        img=axs.imshow(xx,   cmap = cm, norm=norm, interpolation=interpolation)\n#         img=axs.imshow(xx,   cmap = cm, interpolation=interpolation)\n        axs.spines['right'].set_visible(True)\n        axs.spines['left'].set_visible(True)\n        axs.spines['top'].set_visible(True)\n        axs.spines['bottom'].set_visible(True)\n        axs.spines['right'].set_alpha(spines_alpha)\n        axs.spines['left'].set_alpha(spines_alpha)\n        axs.spines['top'].set_alpha(spines_alpha)\n        axs.spines['bottom'].set_alpha(spines_alpha)\n        axs.set_yticks([])\n        axs.set_xticks([])\n        if draw_labels and not draw_pred:\n            axs.set_xlabel(y[i],fontsize=fontsize)\n        if draw_labels and draw_pred:\n            axs.set_xlabel(y[i],fontsize=fontsize)\n        if colorbar:\n            fig.colorbar(img,orientation=\"vertical\", shrink=0.65)\n    plt.show()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(x_train, y_train, [27],  x_size=5,y_size=5, colorbar=True)\nplot_images(x_train, y_train, range(5,41), columns=12)","metadata":{"id":"caN2eFXqbQH-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 4 - Create model\nAbout informations about : \n - [Optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)\n - [Activation](https://www.tensorflow.org/api_docs/python/tf/keras/activations)\n - [Loss](https://www.tensorflow.org/api_docs/python/tf/keras/losses)\n - [Metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)","metadata":{"id":"tAWA64fabQH-"}},{"cell_type":"code","source":"model = keras.models.Sequential()\n\nmodel.add( keras.layers.Input((28,28,1)) )\n\nmodel.add( keras.layers.Conv2D(8, (3,3),  activation='relu') )\nmodel.add( keras.layers.MaxPooling2D((2,2)))\nmodel.add( keras.layers.Dropout(0.2))\n\nmodel.add( keras.layers.Conv2D(16, (3,3), activation='relu') )\nmodel.add( keras.layers.MaxPooling2D((2,2)))\nmodel.add( keras.layers.Dropout(0.2))\n\nmodel.add( keras.layers.Flatten()) \nmodel.add( keras.layers.Dense(100, activation='relu'))\nmodel.add( keras.layers.Dropout(0.5))\n\nmodel.add( keras.layers.Dense(10, activation='softmax'))","metadata":{"id":"bogkzoiAbQH_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","metadata":{"id":"vHjakjDkbQH_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 5 - Train the model","metadata":{"id":"zAUHRWELbQH_"}},{"cell_type":"code","source":"batch_size  = 128\nepochs      =  10\n\nhistory = model.fit(  x_train, y_train,\n                      batch_size      = batch_size,\n                      epochs          = epochs,\n                      verbose         = 1,\n                      validation_data = (x_test, y_test))","metadata":{"id":"0lX4yqDBbQIA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 6 - Evaluate\n### 6.1 - Final loss and accuracy\nNote : With a DNN, we had a precision of the order of : 97.7%","metadata":{"id":"Fyg4rSiObQIA"}},{"cell_type":"code","source":"score = model.evaluate(x_test, y_test, verbose=0)\n\nprint(f'Test loss     : {score[0]:4.4f}')\nprint(f'Test accuracy : {score[1]:4.4f}')","metadata":{"id":"grrUG8fDbQIA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.2 - Plot history","metadata":{"id":"jiCIpfLybQIB"}},{"cell_type":"code","source":"def plot_history(history, figsize=(8,6), \n                 plot={\"Accuracy\":['accuracy','val_accuracy'], 'Loss':['loss', 'val_loss']}):\n    \"\"\"\n    Show history\n    args:\n        history: history\n        figsize: fig size\n        plot: list of data to plot : {<title>:[<metrics>,...], ...}\n    \"\"\"\n    fig_id=0\n    for title,curves in plot.items():\n        plt.figure(figsize=figsize)\n        plt.title(title)\n        plt.ylabel(title)\n        plt.xlabel('Epoch')\n        for c in curves:\n            plt.plot(history.history[c])\n        plt.legend(curves, loc='upper left')\n        \n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history, figsize=(6,4))","metadata":{"id":"mU1we7aDbQIB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.3 - Plot results","metadata":{"id":"7AkgcDbrbQIB"}},{"cell_type":"code","source":"#y_pred   = model.predict_classes(x_test)           Deprecated after 01/01/2021 !!\n\ny_sigmoid = model.predict(x_test)\ny_pred    = np.argmax(y_sigmoid, axis=-1)\n\nplot_images(x_test, y_test, range(0,200), columns=12, x_size=1, y_size=1, y_pred=y_pred)","metadata":{"id":"q6PDZ36dbQIB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.4 - Plot some errors","metadata":{"id":"fU46r6cBbQIC"}},{"cell_type":"code","source":"errors=[ i for i in range(len(x_test)) if y_pred[i]!=y_test[i] ]\nerrors=errors[:min(24,len(errors))]\nplot_images(x_test, y_test, errors[:15], columns=6, x_size=2, y_size=2, y_pred=y_pred)","metadata":{"id":"lkFnbCGdbQIC","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"todo\">\n    A few things you can do for fun:\n    <ul>\n        <li>Changing the network architecture (layers, number of neurons, etc.)</li>\n        <li>Display a summary of the network</li>\n        <li>Retrieve and display the softmax output of the network, to evaluate its \"doubts\".</li>\n    </ul>\n</div>","metadata":{"id":"odHLIO09bQIC"}}]}