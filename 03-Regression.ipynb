{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atelier 2 : Introduction au Machine Learning pour la regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Présentation du problème et du jeux de données\n",
    "\n",
    "### Jeux de données\n",
    "Cet ensemble de données contient des informations collectées par le US Census Service concernant le logement dans la région de Boston. Il a été obtenu à partir des archives StatLib (http://lib.stat.cmu.edu/datasets/boston) et a été largement utilisé par la littérature pour comparer les algorithmes. L'ensemble de données est de petite taille avec seulement 506 cas.\n",
    "\n",
    "La variable cible ici 'medv' représente le prix, dans lequel la valeur médiane d'une maison doit être prédite.\n",
    "\n",
    "Variables\n",
    "    Il y a 14 attributs dans chaque cas de l'ensemble de données. \n",
    "\n",
    "- CRIM - taux de criminalité par habitant par ville\n",
    "- ZN - proportion de terrains résidentiels zonés pour des lots de plus de 25 000 pi.ca.\n",
    "- INDUS - proportion d'acres commerciales non commerciales par ville.\n",
    "- CHAS - Variable fictive Charles River (1 si le tronçon délimite la rivière; 0 sinon)\n",
    "- NOX - concentration en oxydes nitriques (parties pour 10 millions)\n",
    "- RM - nombre moyen de pièces par logement\n",
    "- AGE - proportion de logements occupés par le propriétaire construits avant 1940\n",
    "- DIS - distances pondérées vers cinq centres d'emploi de Boston\n",
    "- RAD - indice d'accessibilité aux autoroutes radiales\n",
    "- TAXE - taux d'impôt foncier de pleine valeur par 10,000 dollars.\n",
    "- PTRATIO - ratio élèves / enseignant par ville\n",
    "- B - 1000 (Bk - 0,63)^2 où Bk est la proportion de noirs par ville\n",
    "- LSTAT -% de statut inférieur de la population\n",
    "- MEDV - Valeur médiane des logements occupés par le propriétaire en milliers de dollars.\n",
    "    \n",
    "**_Remarque :_** Le jeu de données comporte 506 enregistrements.\n",
    "\n",
    "Note 1 : Un pieds² fait environ 0,092 m²\n",
    "\n",
    "Note 2 : Le fichier de données est sous forme csv, vous le trouverez en : _/datasets/Boston.csv_\n",
    "\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAAAOCAYAAADE+hKfAAAEGWlDQ1BrQ0dDb2xvclNwYWNlR2VuZXJpY1JHQgAAOI2NVV1oHFUUPrtzZyMkzlNsNIV0qD8NJQ2TVjShtLp/3d02bpZJNtoi6GT27s6Yyc44M7v9oU9FUHwx6psUxL+3gCAo9Q/bPrQvlQol2tQgKD60+INQ6Ium65k7M5lpurHeZe58853vnnvuuWfvBei5qliWkRQBFpquLRcy4nOHj4g9K5CEh6AXBqFXUR0rXalMAjZPC3e1W99Dwntf2dXd/p+tt0YdFSBxH2Kz5qgLiI8B8KdVy3YBevqRHz/qWh72Yui3MUDEL3q44WPXw3M+fo1pZuQs4tOIBVVTaoiXEI/MxfhGDPsxsNZfoE1q66ro5aJim3XdoLFw72H+n23BaIXzbcOnz5mfPoTvYVz7KzUl5+FRxEuqkp9G/Ajia219thzg25abkRE/BpDc3pqvphHvRFys2weqvp+krbWKIX7nhDbzLOItiM8358pTwdirqpPFnMF2xLc1WvLyOwTAibpbmvHHcvttU57y5+XqNZrLe3lE/Pq8eUj2fXKfOe3pfOjzhJYtB/yll5SDFcSDiH+hRkH25+L+sdxKEAMZahrlSX8ukqMOWy/jXW2m6M9LDBc31B9LFuv6gVKg/0Szi3KAr1kGq1GMjU/aLbnq6/lRxc4XfJ98hTargX++DbMJBSiYMIe9Ck1YAxFkKEAG3xbYaKmDDgYyFK0UGYpfoWYXG+fAPPI6tJnNwb7ClP7IyF+D+bjOtCpkhz6CFrIa/I6sFtNl8auFXGMTP34sNwI/JhkgEtmDz14ySfaRcTIBInmKPE32kxyyE2Tv+thKbEVePDfW/byMM1Kmm0XdObS7oGD/MypMXFPXrCwOtoYjyyn7BV29/MZfsVzpLDdRtuIZnbpXzvlf+ev8MvYr/Gqk4H/kV/G3csdazLuyTMPsbFhzd1UabQbjFvDRmcWJxR3zcfHkVw9GfpbJmeev9F08WW8uDkaslwX6avlWGU6NRKz0g/SHtCy9J30o/ca9zX3Kfc19zn3BXQKRO8ud477hLnAfc1/G9mrzGlrfexZ5GLdn6ZZrrEohI2wVHhZywjbhUWEy8icMCGNCUdiBlq3r+xafL549HQ5jH+an+1y+LlYBifuxAvRN/lVVVOlwlCkdVm9NOL5BE4wkQ2SMlDZU97hX86EilU/lUmkQUztTE6mx1EEPh7OmdqBtAvv8HdWpbrJS6tJj3n0CWdM6busNzRV3S9KTYhqvNiqWmuroiKgYhshMjmhTh9ptWhsF7970j/SbMrsPE1suR5z7DMC+P/Hs+y7ijrQAlhyAgccjbhjPygfeBTjzhNqy28EdkUh8C+DU9+z2v/oyeH791OncxHOs5y2AtTc7nb/f73TWPkD/qwBnjX8BoJ98VQNcC+8AAAZpSURBVGgF7ZcvtBNHFMZbQFDVlbgOrlVdXKsYHK4r6xiJY+vqSF1l6nCsrOtKXAeH3DqqOjjk1uHo70tmymTYl01CkvPgvO+cX+69373zZzev6eGzzz5cFVssDtjGsUZrr3S+N2A56gFcvffzvfOP9iT9kbQwggcLDSxgiJHwv5ZkVaxq4gLeQg/JlzeCooGkZUqu4knfgL6HFhSlbvV59XH1BnZ4A56ZxcRc7ln6+gMr1WP8mZkNuc3qlMpzqbhEUfe9zNr3fm3xMJ7aFN4xy33vd8yz5/a6DHcrv4+5O5+8f22PE0ycDdkaR95ldUodyR3QA1dQg4dSHsOV5iWodd/LrH3up/c/Zg+jWoTMO3ZaH3vDI+53Ge7WHPF5jrLVjT12ccwuoIMkQzKmIovyHHRgoIWLpFkDAU6lio31b+NX4EFnHks1GwkpgIdcOtuCgR4syOtghFOr4QCdq1hBDQ6SVCe/I29ivSSeWjr7UTzkJ+IYc/kDVGDBQAcNyFM+wqcuPW8/8ZBt9EPsaa6CAeroKRc7ae6H4C67PAZt/lexoynqsuwxPHxbNopalzUQYEot5g9Tjcz7jVznTanGXEID49TAB3iOtRYUpR6CElRBAJ3bZdGSB9DsCJKBAKeSzglxc0tM51bkNXRgY2yI6ncxakbf4XM4pgybtdCD8gWothBAcrAECwPU0IMH1ZKFECF8MjI8iZiSwWxgCQ46kEaoYQHSsA7zn3M/BPryfwEDDnIZim0HVbHfEsUSLpJmL5LWbVt70brke5IaxmQUsaIuf6y+wtOPYC69i1yGYgHaO2kgcaCzlmCgB6kGrwSZ1ef6x6Ihb0H9i2RpvM2aU/fTD/WYzZTpEI2e6GABBjqQKlBPUi7VoHyEHhYwQC71D3l/DetctpFy7SVCjD1RkudhBAuSvBYWsAQPPZSyGB/67so996l1z/L9fIk39/dlmdFzJVkSH4v8OYfo1UTlARzspWs7Tgfm/I6zaawlWYCL0RDPLcuBIxiwoJc1pc8xt/HvxKIGbwDtn8tQhGgopr4l95BLvQ7STN4r8233U29qD4MfIJehSLND1rDkPquVLkCzmuuhgSnN3U39UsvCSPuP0VcMMbdEH/MUKpI0O5A3qTER5+43seSo1tz5U+8nv4ClqDPDkPtY69klCx4O0o09VvliNlDnl8vbjqKPhqKHp3APpjROmdFriPWWvlo+orxUwPClmdU6u+zbCQ9rQxXVsOGsC/n9hK//A/jo2yyP1tbgi66lLr1iZFVaPsu7NHgOcunOIkTTEj20EECqISgpNFL7wrMTXjHyXql9HFgoZTGW0VTuIYA8Cw20MCVfmJa69IqRo5bjxHlTXnmoyYyafIh1RTQxz4OlWEZDuQcDDYwg1eChhw1t+yGoNibfL8L71sqxfD6ADpJakn9AcZnMGOsJLx/pKcQh8nFRRRzBQIBjyLOJyzYy5DongImxIw4xf06U6nU4y6fhFAs9SC10EECS30EFAaR6HVafIebyRBvrUwWfbayzDHQxBmIVc8KGApWFDo4lx0aP4E7cUPepwcW6I44gX+rBwxKOoZpNHkMFt8HBH3Av5oSV54gNWFiApDWSgQFaSDOWvIcNXd+o1oUhaOHLdbk6IJCPsc6DpfDwBiQHNbwCKaw+15fQv2FvggUPSQ9JnqTiBFEP3UAFBtJzkV4oS8df2F03AmEEC9pb6uBr0PsIoH7Kn5F/B5Jffb77cKTdu3I2s0z42an1875mzoAF3cFDkno34WVEd9edX0CSnq2Bh6D8DczJMuDnhop+Tf0aQvR1zhjzJ8T7cBP66Bmi7jOA7i//V5iTZcDPDdEf4W/Q3pLuozyApP4LeK0Cqe9B/pwcA93MkM76HvTfzc+gc74BPaN6UgCdewtaaGLeE6UADp6B1mhGd1Z+VFl20+aHShd3hy4+4Tp7wr2ntvZT5hbPbumlliGxqTgwVqx7CncjjriL7C5DxYz+jnTertK8i8M10cd8Lti5gTP0dfdzyXNQeq/KDTSwoesb1f5FYMl9GOAN7CNdzoF+4S6bwhkvZDlrhFugd6h8TmFugH4D/Q5z20b03X4BtyOe+BrmFOYGJvo/4u1z3xfM11CB7rmAEeYU5gbO0NfdzyXDQc+yw1T/ntVHTRcH7OZYoy/xSqd5Ax/bu61P8xqudt3lDfwH7Y1uaTUENgcAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression linéaire multivariée\n",
    "\n",
    "Dans ce notebook, nous allons voir toutes les étapes permenntant de résoudre un problème d'apprentissage automatique.\n",
    "Les problèmes d'apprentissage automatique sont généralement divisés en deux groupes. \n",
    "\n",
    "\n",
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<center>\n",
    "  <mi>f</mi>\n",
    "  <mo>:</mo>\n",
    "  <mi>x</mi>\n",
    "  <mo stretchy=\"false\">&#x2192;<!-- → --></mo>\n",
    "  <mi>y</mi>\n",
    "</math></center>\n",
    "\n",
    "\n",
    " -  x représente l'entrée\n",
    " -  y représente la valeur de <mi>f(x)</mi>.\n",
    "\n",
    "\n",
    "1. **Classification** - Si y est une variable discrète ou catégorique.\n",
    "Les prédictions de la classification peuvent être évaluées à l'aide de la précision, contrairement aux prévisions de la régression.\n",
    "\n",
    "2. **Régression** - Si y est un nombre réel ou continu.\n",
    "\n",
    "\n",
    "Nous pouvons facilement comprendre que notre problème est un problème de régression, car nous voulons prédire le prix, qui est un nombre réel.\n",
    "\n",
    "Remarque: La variable cible est généralement prédite non seulement avec une seule variable prédictive mais avec plusieurs. Dans ce cas, on parle de  Multivariate Regression (régression linéaire multivariée). Dans ce qui va suivre, on va implémenter les méthodes les plus connues en utilisant les libraires de Machine learning de Python.\n",
    "\n",
    "### Multivariate Regression\n",
    "\n",
    "Quand une variable cible est le fruit de la corrélation de plusieurs variables prédictives, on parle de Multivariate Regression pour faire des prédictions. Prenons, par exemple, la prédiction du prix d’une voiture. Le prix est la variable cible, les variables prédictives peuvent être : nombre de kilomètres au compteur, le nombre de cylindres, nombre de portes…etc. Toutes ces variables prédictives seront utilisées dans notre modèle de régression linéaire multivariée pour trouver une fonction prédictive.\n",
    "\n",
    "Dans le cas de régression linéaire multivariée, la fonction prédictive s’écrira sous la forme :\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\n",
    "\n",
    "A noter que :\n",
    "\n",
    "        ε : est une constante\n",
    "        α, β, γ…. : représente les coefficients de notre fonction prédictive F(X)\n",
    "        X : est un vecteur/tableau de variables prédictives. Pour l’exemple de prédiction du prix de la maison, la taille du vecteur X sera égale à 2 (superficie en pied2 et le nombre de chambres)\n",
    "          xi : représente la ième variable prédictive.\n",
    "\n",
    "Maintenant qu’on sait à quoi ressemblera notre fonction prédictive ainsi que nos données, essayons d’appliquer ce concept dans un cas concret en le codant en Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données\n",
    "\n",
    "On commence par charger les données contenues dans le fichier csv. Python propose via sa librairie Pandas des classes et fonctions pour lire divers formats de fichiers notamment les fichiers Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"datasets/Boston.csv\")\n",
    "df=df.drop(columns=['Unnamed: 0'], axis =1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.medv.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on vérifie s'il n'y pas des valeurs nulles\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#etude de la correlation\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "\n",
    "matrice_corr = df.corr().round(1)\n",
    "matrice_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data=matrice_corr, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le prix a une forte corrélation avec LSTAT et RM. Cependant il ne faut pas négliger les autres attributs comme CRIM,ZN,INDUS… car leur corrélation sont pas proches de 0. \n",
    "Il faut savoir que lorsqu’on fait une regression linéaire on pose certaines hypothèses notamment la Non colinéarité des variables explicatives (une variable explicative ne doit pas pouvoir s’écrire comme combinaison linéaire des autres).\n",
    "\n",
    "TAX et RAD ont une corrélation de 0.9; NOX et  DIS et AGE ont une corrélation de 0.7 ; DIS et INDUS ont une corrélation de 0.7.\n",
    "Après une analyse minutieuse nous choisissons : LSAT, RM,TAX,PTRATIO\n",
    "\n",
    "On utilise pour le modèle les variables choisies ci-dessus ensuite on divise notre jeu de données en 2 parties (80%, pour l’apprentissage et les 20% restant pour le test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on utilise seulement 4 variables explicatives\n",
    "X = df[['lstat','rm','tax','ptratio']]\n",
    "Y= df[['medv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base d'apprentissage et base de test\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrainement du modèle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lmodellineaire = LinearRegression()\n",
    "lmodellineaire.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_train_predict = lmodellineaire.predict(X_train)\n",
    "rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))\n",
    "r2 = r2_score(Y_train, y_train_predict)\n",
    " \n",
    "print('La performance du modèle sur la base dapprentissage')\n",
    "print('--------------------------------------')\n",
    "print('Lerreur quadratique moyenne est {}'.format(rmse))\n",
    "print('le score R2 est {}'.format(r2))\n",
    "print('\\n')\n",
    " \n",
    "# model evaluation for testing set\n",
    "y_test_predict = lmodellineaire.predict(X_test)\n",
    "rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
    "r2 = r2_score(Y_test, y_test_predict)\n",
    " \n",
    "print('La performance du modèle sur la base de test')\n",
    "print('--------------------------------------')\n",
    "print('Lerreur quadratique moyenne est {}'.format(rmse))\n",
    "print('le score R2 est {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on utilise toutes les variables explicatives\n",
    "X = df[['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
    "       'ptratio', 'black', 'lstat']]\n",
    "Y= df[['medv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base d'apprentissage et base de test\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state=5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "clf = Ridge()\n",
    "clf.fit(X_train, Y_train)\n",
    "train_score = clf.score(X_train, Y_train)\n",
    "print('train score = ',train_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prédiction\n",
    "pred = clf.predict(X_test)\n",
    "mse = mean_squared_error(pred  , Y_test)\n",
    "rmse = np.sqrt(mean_squared_error(pred,Y_test))\n",
    "#print(' MSE = ',mse )\n",
    "print(' RMSE = ',rmse )\n",
    "r2 = r2_score(Y_test, pred)\n",
    "print(' R2 = ',r2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "clf = Lasso()\n",
    "clf.fit(X_train, Y_train)\n",
    "train_score = clf.score(X_train, Y_train)\n",
    "print('train score = ',train_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prédiction\n",
    "pred = clf.predict(X_test)\n",
    "mse = mean_squared_error(pred  , Y_test)\n",
    "rmse = np.sqrt(mean_squared_error(pred,Y_test))\n",
    "#print(' MSE = ',mse )\n",
    "print(' RMSE = ',rmse )\n",
    "r2 = r2_score(Y_test, pred)\n",
    "print(' R2 = ',r2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "clf = ElasticNet()\n",
    "clf.fit(X_train, Y_train)\n",
    "train_score = clf.score(X_train, Y_train)\n",
    "print('train score = ',train_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prédiction\n",
    "pred = clf.predict(X_test)\n",
    "mse = mean_squared_error(pred  , Y_test)\n",
    "rmse = np.sqrt(mean_squared_error(pred,Y_test))\n",
    "#print(' MSE = ',mse )\n",
    "print(' RMSE = ',rmse )\n",
    "r2 = r2_score(Y_test, pred)\n",
    "print(' R2 = ',r2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode de Random Forest\n",
    "Pour une documentation complète : \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "clf = RandomForestRegressor(max_depth=None, n_estimators=100)\n",
    "clf.fit(X_train, Y_train)# .values.ravel())\n",
    "\n",
    "train_score = clf.score(X_train, Y_train)\n",
    "print('train score = ',train_score )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = clf.predict(X_test)\n",
    "mse = mean_squared_error(ypred  , Y_test)\n",
    "rmse = np.sqrt(mean_squared_error(ypred,Y_test))\n",
    "print(' Random Forest RMSE = ',rmse )\n",
    "r2 = r2_score(Y_test, ypred)\n",
    "print(' Random Forest R2 = ',r2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour aller plus loin :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation des données et feature Scaling\n",
    "\n",
    "Vous l’avez peut être remarqué, notre exemple comporte des variables prédictives avec des ordres de grandeurs très différents. En effet, le nombre de chambre d’une maison est généralement compris entre 1 et 10 alors que la superficie se compte en quelques milliers de pieds2.\n",
    "\n",
    "Pour appliquer l’algorithme Multivariate Regression, il est nécessaire que les variables prédictives faisant partie du modèle prédictif soient du même ordre de grandeur. Généralement, il faut que la valeur de chaque variable prédictive soient compris (approximativement) entre -1 et 1. Si certaines valeurs dépassent un peu (par exemple -2 , 1.5…) ce n’est pas très grave.\n",
    "\n",
    "Pour ramener nos variables prédictives au même ordre de grandeur, nous appliquerons un procédé qui s’appelle : _features scaling_\n",
    "\n",
    "La librairie _Scikit learn_ de Python propose plusieurs classes et méthodes pour faire de la préparation de données (_Data pre-processing_) pour les algorithmes de Machine Learning. Le package sklearn.preprocessing propose la classe _StandardScaler_ qui permettra de faire du _features scaling_ sur toutes nos variables prédictives.\n",
    "\n",
    "(voir tutoriel : https://www.datacorner.fr/feature-scaling/ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "scale = StandardScaler()\n",
    "#X_scaled = scale.fit_transform(X[['x1','X2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "##decouper le data set en 30% pour test et 70% pour train\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
